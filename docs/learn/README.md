# 深度学习架构文档

本目录包含了深度学习中主要架构的详细文档，涵盖了从传统神经网络到现代 Transformer 架构的完整内容。

## 文档列表

### 1. [循环神经网络 (RNN)](./rnn.md)
- **概述**：处理序列数据的经典架构
- **核心内容**：
  - 基础 RNN 原理和数学公式
  - LSTM 和 GRU 变体详解
  - 双向 RNN 和序列到序列模型
  - 训练算法（BPTT）和梯度问题
  - 完整的 PyTorch 实现代码
  - 应用领域和局限性分析

### 2. [卷积神经网络 (CNN)](./cnn.md)
- **概述**：计算机视觉任务的标准架构
- **核心内容**：
  - 卷积操作和前向传播数学原理
  - 经典架构演进（LeNet、AlexNet、VGG、ResNet）
  - 现代高效架构（EfficientNet、MobileNet）
  - 训练技巧和优化策略
  - 完整的 PyTorch 实现代码
  - 应用领域和性能分析

### 3. [Transformer 架构](./transformer.md)
- **概述**：基于注意力机制的现代架构
- **核心内容**：
  - 自注意力机制和多头注意力
  - 位置编码和前馈网络
  - 编码器-解码器结构
  - 现代变体（BERT、GPT、T5）
  - 高效的 Transformer 变体
  - 完整的 PyTorch 实现代码

## 学习路径建议

### 初学者路径
1. **CNN** → 理解卷积操作和空间特征提取
2. **RNN** → 学习序列建模和循环结构
3. **Transformer** → 掌握注意力机制和现代架构

### 进阶学习
- 深入理解各架构的数学原理
- 实现完整的训练和推理代码
- 探索架构变体和优化技巧
- 了解实际应用场景和性能对比

## 数学符号说明

文档中使用的数学符号遵循标准约定：
- 矩阵用大写字母表示：$W, Q, K, V$
- 向量用小写字母表示：$x, h, y$
- 标量用斜体表示：$d_k, n, t$
- 函数用正体表示：$\text{softmax}, \text{ReLU}$

## 代码实现

所有文档都包含完整的 PyTorch 实现代码，包括：
- 基础架构实现
- 训练和推理代码
- 实际应用示例
- 性能优化技巧

## 参考文献

每个文档都包含详细的参考文献，涵盖：
- 原始论文和开创性工作
- 重要的改进和变体
- 实际应用案例
- 最新的研究进展

## 贡献指南

欢迎对文档进行改进和补充：
- 修正错误和更新内容
- 添加新的架构和变体
- 提供更多的代码示例
- 分享实际应用经验

---

*最后更新：2024年*
